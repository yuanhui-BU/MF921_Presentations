\documentclass{beamer}

% \usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}
\usepackage{lmodern}   % modern Latin Modern fonts
\usepackage{textcomp}  % provides \textquoteright
\usepackage{lmodern} % Latin Modern fonts with T1 shapes


\usepackage{graphicx}
\usepackage{ragged2e} % for generating dummy text
\usepackage[backend=biber,style=authoryear]{biblatex}
% \addbibresource{references.bib}

\usetheme{Madrid}
\usecolortheme{default}
\usefonttheme{professionalfonts} % keeps proper math fonts

\usepackage{amsmath,amssymb,amsfonts} % math symbols (\mathcal, \mathbb, etc.)
\usepackage{mathrsfs}                 % optional: \mathscr for fancy script

% \setbeamercovered{invisible} 
\setbeamercovered{transparent}


\title{MF921 Topics in Dynamic Asset Pricing}
\subtitle{Week 4}
\author{Yuanhui Zhao}
\date{Boston University}

\begin{document}
\frame{\titlepage}
% \begin{frame}
% \frametitle{Outline}
% \tableofcontents
% \end{frame}

\section{Background}
\begin{frame}{Background}

    {\footnotesize \footnotesize
    \par Recall The Double Exponential Jump Diffusion Model:
    \begin{align*}
        \frac{dS(t)}{S(t^{-})} = \mu dt + \sigma dW(t) + d\left(\sum_{i=1}^{N(t)} (V_i - 1)\right)
    \end{align*}
    \par\begin{itemize}
    \item \( W(t) \): Brownian motion under the real-world measure.
    \item \( N(t) \): Poisson process with rate \(\lambda\).
    \item \( V_i \): multiplicative jump sizes, i.i.d. random variables.
    \item \( Y = \log(V) \), the jump sizes follow double exponential law:
    \end{itemize}   
    \begin{align*}
        f_Y(y) = p \eta_1 e^{-\eta_1 y} \mathbf{1}_{y \geq 0} + q \eta_2 e^{\eta_2 y} \mathbf{1}_{y < 0}
    \end{align*}
    \par with parameters:
    \begin{itemize}
        \item \( p, q \geq 0, p + q = 1 \): probabilities of upward/downward jumps.
        \item \(\eta_1 > 1\): rate for upward jumps.
        \item \(\eta_2 > 0\): rate for downward jumps.
    \end{itemize}
    }
    
\end{frame}
\begin{frame}{Background Con.}

    {\footnotesize \footnotesize
    \par For option pricing, we switch to a risk-neutral measure \( P^* \), so that the discounted price process is a martingale:
    \begin{align*}
        E^{P^*}[e^{-rt}S(t)] = S(0)
    \end{align*}
    \par Under \( P^* \), the dynamics adjust:
    \begin{align*}
        \frac{dS(t)}{S(t^-)} = (r - \lambda^*(t)\zeta^*)dt + \sigma dW^*(t) + d\left(\sum_{i=1}^{N^*(t)}(V_i^*-1)\right)
    \end{align*}
    \par \pause where:
    \begin{itemize}
        \item \( W^*(t) \): Brownian motion under \( P^* \),
        \item \( N^*(t) \): Poisson process with intensity \( \lambda^* \),
        \item \( V^* = e^{Y^*} \): jump multiplier with new parameters \( (p^*, q^*, \eta_1^*, \eta_2^*) \),
        \item \( \zeta^* = E^{P^*}[V^*] - 1 = \frac{p^{*}\eta_{1}^{*}}{\eta_{1}^{*}-1} + \frac{q^{*}\eta_{2}^{*}}{\eta_{2}^{*}+1} - 1\) is mean percentage jump size.
    \end{itemize}
    \par The log-price process:  
    \begin{align*}
        X(t) = \log\left(\frac{S(t)}{S(0)}\right) = \left(r - \frac{1}{2}\sigma^2 - 
    \lambda^*\zeta^*\right)t + \sigma W^*(t) + \sum_{i=1}^{N^*(t)} Y_i^*,\;\;X(0)=0
    \end{align*}
    }
\end{frame}
\begin{frame}{Some Useful Formulas Con}

    {\footnotesize \footnotesize
    \par Moment Generating Function of the log-price process, \( X(t) \):
    \begin{align*}
        \mathbb{E}^{\mathbb{P}^*} \left[ e^{\theta X(t)} \right] = \exp\{G(\theta)t\}
    \end{align*}
    \par Where the function $G(\cdot)$ is defined as:
    \begin{align*}
        G(x) = x \left( r - \frac{1}{2} \sigma^2 - \lambda \zeta \right) + \frac{1}{2} x^2 \sigma^2 
        + \lambda \left( \frac{p \eta_1}{\eta_1 - x} + \frac{q \eta_2}{\eta_2 + x} - 1 \right)
    \end{align*}
    \par  \pause \textbf{Note}: Lemma 3.1 in Kou and Wang (2003) shows that the 
    equation \( G(x) = \alpha, \forall \alpha > 0 \), has exactly 
    four roots: \(\beta_{1,\alpha}\), \(\beta_{2,\alpha}\), \(-\beta_{3,\alpha}\), and \(-\beta_{4,\alpha}\), where: 
    \begin{align*}
        0 &< \beta_{1,\alpha} < \eta_1 < \beta_{2,\alpha} < \infty\\
        0 &< \beta_{3,\alpha} < \eta_2 < \beta_{4,\alpha} < \infty
    \end{align*}
    \par These roots determine the structure of Laplace transforms for first passage times.
    }
    
\end{frame}
\begin{frame}{Some Useful Formulas Con}

    {\footnotesize \footnotesize
    \par Infinitesimal Generator of the log-price process, \( X(t) \):
    \vspace{1em}
    \begin{align*}
        (\mathcal{L}V)(x) = \frac{1}{2}\sigma^2 V''(x) + \left(r - \frac{1}{2}\sigma^2 
        - \lambda\zeta\right)V'(x) + \lambda \int_{-\infty}^{\infty}\left(V(x+y) - V(x)\right)f_Y(y)\,dy
    \end{align*}
    \vspace{1em}
    \par  \pause  The generator describes how expectations of functions of \( X(t) \) evolve in time:
    \vspace{1em}
    \begin{align*}
        \frac{d}{dt}\mathbb{E}[V(X_t)] = \mathbb{E}[(\mathcal{L}V)(X_t)]
    \end{align*}
    \vspace{1em}
    \par They provide the mathematical foundation to derive option pricing formulas.



    }
    
\end{frame}

\begin{frame}{Part I}
    \begin{center}
        Option Pricing Under a Double Exponential Jump Diffusion Model
    \end{center}
    \vspace{2em}
    \begin{center}
        S.G. Kou\\
        Hui Wang
    \end{center}
    \vspace{3em}
    \par Proof of two Theorems. The Laplace transform of lookback option and barrier option.
 \end{frame}
\section{Pricing Path-Dependent Options}
\begin{frame}{Lookback Options}

    {\footnotesize \footnotesize
    \par Consider a lookback put option with an initial "prefixed maximum" \( M \geq S(0) \):
    \vspace{1em}
    \begin{align*}
        LP(T) &= \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} \left( \max\{M, \max_{0 \leq t \leq T} S(t)\} - S(T) \right) \right]\\
        & =   \mathbb{E}^{\mathbb{P}^*}\left[ e^{-rT} \max\{M, \max_{0 \leq t \leq T} S(t)\} \right] - S(0)\\
    \end{align*}

    \par \pause  You need the joint distribution of $\max S(t)$ and $S(T)$, which is complicated for jump processes. 
    Laplace transforms convert a complicated path integral over time into a function of roots of $G(x)$
    which we can solve algebraically.
    }
    
\end{frame}

\begin{frame}{Lookback Options Con.}

    \par Theorem:
    {\footnotesize \footnotesize
    
    \vspace{1em}
    \par Using the notations \(\beta_{1,\alpha+r}\) 
    and \(\beta_{2,\alpha+r}\) as in early silde, the Laplace transform of the lookback put is given by:
    \vspace{1em}
    {\footnotesize \tiny
    \begin{align*}
        \hat{L}(T) = \int_0^\infty e^{-\alpha T} \mathrm{LP}(T)  dT = \frac{S(0)A_\alpha}{C_\alpha} \left( \frac{S(0)}{M} \right)^{\beta_{1,\alpha+r}-1} 
        + \frac{S(0)B_\alpha}{C_\alpha} \left( \frac{S(0)}{M} \right)^{\beta_{2,\alpha+r}-1}  
        + \frac{M}{\alpha+r} - \frac{S(0)}{\alpha}
    \end{align*}
    }
    \vspace{1em}
    \par  \pause  For all \(\alpha > 0\); here:
    \vspace{1em}
    \begin{align*}
        A_\alpha &= \frac{(\eta_1 - \beta_{1,\alpha+r}) \beta_{2,\alpha+r}}{\beta_{1,\alpha+r} - 1} \\
        B_\alpha &= \frac{(\beta_{2,\alpha+r} - \eta_1) \beta_{1,\alpha+r}}{\beta_{2,\alpha+r} - 1}\\
        C_\alpha &= (\alpha + r) \eta_1 (\beta_{2,\alpha+r} - \beta_{1,\alpha+r})
    \end{align*}

    }
    
\end{frame}

\begin{frame}{Proof}

    {\footnotesize \footnotesize
    \par Lemma :  \(\lim\limits_{y\to\infty}e^{y}\mathbb{P}^{*}[M_{X}(T)\geq y]=0\), \(\forall T\geq 0\). \(M_{X}(T):=\max\limits_{0\leq t\leq T}X(t)\)
    \par [Proof]
    \vspace{1em}
    \par Given \(\theta\in(-\eta_{2},\,\eta_{1})\), $\mathbb{E}^{\mathbb{P}^*}[e^{\theta X(t)}]<\infty$, 
    by stationary independent increments we can get that the process \(\{e^{\theta X(t)-G(\theta)t}; t\geq 0\}\) is a martingale.
     \vspace{1em}
    \par  \pause Observe that $G(x)$ is continuous and \(G(1)=r>0\), thus we can fix an \(\theta\in(1,\,\eta_{1})\) such that \(G(\theta)>0\).
     Let $\tau_y = \inf\{t \geq 0 : X(t) \geq y\}$. By Optional Sampling Theorem:
      \vspace{1em}
    \begin{align*}
      1 = \mathbb{E}^{\mathbb{P}^*}[M_{\tau_y \land T}]  \mathbb{E}^{\mathbb{P}^*} \left[ e^{\theta X(\tau_y \land T)} e^{-G(\theta)(\tau_y \land T)} \right] 
      \geq e^{\theta y} e^{-G(\theta)T} \mathbb{P}^* (\tau_y \leq T)
    \end{align*}
     \vspace{1em}
    \par  \pause Thus $e^{\theta y} \mathbb{P}^* (\tau_y \leq T) \leq e^{G(\theta)T}$. Since $\theta > 1$, then we have:
     \vspace{1em}
    \begin{align*}
      e^y \mathbb{P}^* (M_X(T) \geq y) = 
      e^{(1-\theta)y} \left[ e^{\theta y} \mathbb{P}^* (\tau_y \leq T) \right] \leq e^{(1-\theta)y} e^{G(\theta)T} \xrightarrow{y \to \infty} 0
    \end{align*}
    \par This will use to justify the boundary term vanishing in the integration-by-parts step later.
    }
    
\end{frame}
\begin{frame}{Proof Con}

    {\footnotesize \footnotesize
    \par Given $s = S(0)$ and $M$ are constants, \(\max\limits_{0 \leq t \leq T} S(t) = s  e^{M_X(T)}\), the lookback put as:
    \vspace{1em}
    \begin{align*}
      LP(T) = \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} \max\{M, se^{M_X(T)}\} \right] - s
    \end{align*}
     \vspace{1em}
    \par  \pause  Letting \(z=\log(M/s)\geq 0\), define:
     \vspace{1em}
    \begin{align*}
      L(s, M; T)  :&= \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} \max\{M, se^{M_X(T)}\} \right] \\
      &= s  \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} \max\{e^z, e^{M_X(T)}\} \right]\\
      &  = s  \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} \left( e^{M_X(T)} - e^z \right) \mathbf{1}_{\{M_X(T) \geq z\}} \right] + s  e^z  e^{-rT}\\
    \end{align*}
    }
    
\end{frame}
\begin{frame}{Proof Con}

    {\footnotesize \footnotesize
    \par Integration by parts:
    {\footnotesize \tiny
    \begin{align*}
      \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} e^{M_X(T)} \mathbf{1}_{\{M_X(T) \geq z\}} \right] 
      & = e^{-rT} \int_{z}^{\infty} e^y  d(1-\mathbb{P}^* [M_X(T) \geq y])\\
      & = -e^{-rT} \int_{z}^{\infty} e^y  d\mathbb{P}^* [M_X(T) \geq y]\\
      & = -e^{-rT} \left\{ \left(-e^y \mathbb{P}^* [M_X(T) \geq y]\right)\bigg|_0^{\infty} - 
      \int_{z}^{\infty} \mathbb{P}^* [M_X(T) \geq y] e^y  dy \right\}\\
      &= -e^{-rT} \left\{ -e^z \mathbb{P}^* [M_X(T) \geq z] - \int_{z}^{\infty} \mathbb{P}^* [M_X(T) \geq y] e^y  dy \right\}\\
      &= \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} e^z \mathbf{1}_{\{M_X(T) \geq z\}} \right] + e^{-rT} \int_{z}^{\infty} e^y \mathbb{P}^* [M_X(T) \geq y]  dy;\\
    \end{align*}
    }
    \par \pause  Plug back into $ L(s, M; T)$:
    {\footnotesize \tiny
    \begin{align*}
       L(s, M; T) & = s  \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} \left( e^{M_X(T)} - e^z \right) \mathbf{1}_{\{M_X(T) \geq z\}} \right] + s  e^z  e^{-rT}\\
       & =  se^{-rT} \int_{z}^{\infty} e^{y} \mathbb{P}^*[M_X(T) \geq y] dy + Me^{-rT} \\
    \end{align*}
    }
    }
    
\end{frame}
\begin{frame}{Proof Con}

    {\footnotesize \footnotesize
    \par Then take Laplace in maturity and use Fubini Theorem:
    % {\footnotesize \tiny
    \begin{align*}
      \int_{0}^{\infty} e^{-\alpha T} L(s, M; T) dT 
    &= s \int_{0}^{\infty} e^{-\alpha T} e^{-rT} \int_{z}^{\infty} e^{y} \mathbb{P}^*[M_X(T) \geq y] dy dT + \frac{M}{\alpha + r} \\
    &= s \int_{z}^{\infty} e^{y} \int_{0}^{\infty} e^{-(\alpha + r)T} \mathbb{P}^*[M_X(T) \geq y] dT dy + \frac{M}{\alpha + r}
    \end{align*}
    
    \par  \pause Follows from Kou and Wang (2003) that:
    \[
    \int_{0}^{\infty} e^{-(\alpha + r)T} \mathbb{P}^*[M_X(T) \geq y] dT = A_1 e^{-y\beta_{1,\alpha+r}} + B_1 e^{-y\beta_{2,\alpha+r}}
    \]

    \[
    A_1 = \frac{1}{\alpha + r} \frac{\eta_1 - \beta_{1,\alpha+r}}{\eta_1} \cdot \frac{\beta_{2,\alpha+r}}{\beta_{2,\alpha+r} - \beta_{1,\alpha+r}}, \quad
    B_1 = \frac{1}{\alpha + r} \frac{\beta_{2,\alpha+r} - \eta_1}{\eta_1} \cdot \frac{\beta_{1,\alpha+r}}{\beta_{2,\alpha+r} - \beta_{1,\alpha+r}}.
    \]
    }
    
\end{frame}
\begin{frame}{Proof Con}

    {\footnotesize \footnotesize
    \par Note that \(\beta_{2,\alpha+r} > \eta_1 > 1\), \(\beta_{1,\alpha+r} > \beta_{1,r} = 1\). 
    Therefore:
\begin{align*}
\int_{0}^{\infty} e^{-\alpha T} L(s, M; T) dT 
&= s \int_{z}^{\infty} e^{y} A_1 e^{-y\beta_{1,\alpha+r}} dy + s \int_{z}^{\infty} e^{y} B_1 e^{-y\beta_{2,\alpha+r}} dy + \frac{M}{\alpha + r} \\
&= s A_1 \frac{e^{-z(\beta_{1,\alpha+r}-1)}}{\beta_{1,\alpha+r}-1} + s B_1 \frac{e^{-z(\beta_{2,\alpha+r}-1)}}{\beta_{2,\alpha+r}-1} + \frac{M}{\alpha + r} \\
&= s \frac{A_{\alpha}}{C_{\alpha}} e^{-z(\beta_{1,\alpha+r}-1)} + s \frac{B_{\alpha}}{C_{\alpha}} e^{-z(\beta_{2,\alpha+r}-1)} + \frac{M}{\alpha + r}.
\end{align*}

\par This yields the Laplace transform we obtained in the Theorem.

    % \begin{align*}
    % \int_{0}^{\infty} e^{-\alpha T} L(s, M; T) dT 
    % &= s \int_{z}^{\infty} e^{y} A_1 e^{-y\beta_{1,\alpha+r}} dy + s \int_{z}^{\infty} e^{y} B_1 e^{-y\beta_{2,\alpha+r}} dy + \frac{M}{\alpha + r} \\
    % &= s A_1 \frac{e^{-z(\beta_{1,\alpha+r}-1)}}{\beta_{1,\alpha+r}-1} + s B_1 \frac{e^{-z(\beta_{2,\alpha+r}-1)}}{\beta_{2,\alpha+r}-1} + \frac{M}{\alpha + r} \\
    % &= s \frac{A_{\alpha}}{C_{\alpha}} e^{-z(\beta_{1,\alpha+r}-1)} + s \frac{B_{\alpha}}{C_{\alpha}} e^{-z(\beta_{2,\alpha+r}-1)} + \frac{M}{\alpha + r}
    % \end{align*}

    % \par This yields the Laplace transform we obtained in the Theorem.
    }
    
\end{frame}

\begin{frame}{Barrier Options}


    {\footnotesize \footnotesize
    \par Consider the up-and-in call (UIC) option with the barrier level $H$ ($H>S(0)$):
    \vspace{1em}
    \begin{align*}
        UIC = E^{\mathbb{P}^*}[e^{-rT}(S(T) - K)^+I{\{ \max\limits_{0 \leq t \leq T} S(t) \geq H \}}]
    \end{align*}
    \vspace{1em}
    \par  \pause For any given probability \( P \), define:
    \vspace{1em}
    \begin{align*}
        \Psi(\mu, \sigma, \lambda, p, \eta_1, \eta_2; a, b, T):= P[Z(T) \geq a, \max_{0 \leq t \leq T} Z(t) \geq b]
    \end{align*}
    \vspace{1em}
    \par  \pause where under \( P, Z(t) \) is a double exponential jump diffusion 
    process with drift \( \mu \), volatility \( \sigma \), and jump rate \( \lambda \), i.e., \( Z(t) = \mu t + \sigma W(t) + \sum_{i=1}^{N(t)} Y_i \), 
    and \( Y \) has a double exponential distribution with 
    density \( f_Y(y) \sim p \cdot \eta_1 e^{-\eta_1 y} 1_{\{y \geq 0\}} + q \cdot \eta_2 e^{y \eta_2} 1_{\{y < 0\}} \).
    }
    
    
\end{frame}
\begin{frame}{Barrier Options Con.}

    \par Theorem:
    \vspace{1em}
    {\footnotesize \footnotesize
    
    \par The price of the UIC option is obtained as:
    \vspace{1em}
    \begin{align*}
        \text{UIC} = & S(0) \Psi \left( r + \frac{1}{2} \sigma^2 - \lambda \zeta, \sigma, \tilde{\lambda}, \tilde{p}, \tilde{\eta}_1, \tilde{\eta}_2; \right. 
        \left. \log \left( \frac{K}{S(0)} \right), \log \left( \frac{H}{S(0)} \right), T \right) \\
        & -Ke^{-rT} \cdot \Psi \left( r - \frac{1}{2} \sigma^2 - \lambda \zeta, \sigma, \lambda, p, \eta_1, \eta_2; \right. 
         \left. \log \left( \frac{K}{S(0)} \right), \log \left( \frac{H}{S(0)} \right), T \right)
    \end{align*}
    \vspace{1em}
    \par  \pause where \( \tilde{p} = (p/(1 + \zeta)) \cdot (\eta_1 / (\eta_1 - 1)), \tilde{\eta}_1 
    = \eta_1 - 1, \tilde{\eta}_2 = \eta_2 + 1, \tilde{\lambda} = \lambda(\zeta + 1) \), 
    with \(\zeta = E^{P^*}[V] - 1 = \frac{p\eta_{1}}{\eta_{1}-1} + \frac{q\eta_{2}}{\eta_{2}+1} - 1\). 
    The Laplace transforms of \( \Psi \) is computed explicitly in Kou and Wang (2003).
    }
    
\end{frame}
\begin{frame}{Proof}

    
    {\footnotesize \footnotesize
    \par Theorem 3.1 in Kou and Wang (2003):
    \vspace{1em}
    \par For any \(\alpha \in (0, \infty)\), let \(\beta_{1,\alpha}\) and \(\beta_{2,\alpha}\) be the only two positive roots of the equation  
    \[
    \alpha = G(\beta),
    \]  
    where \(0 < \beta_{1,\alpha} < \eta_1 < \beta_{2,\alpha} < \infty\). Then we have the following results concerning the Laplace transforms of \(\tau_b\) and \(X_{\tau_b}\):  
         \pause 
    \[
    \mathbb{E}[e^{-\alpha\tau_b}] = \frac{\eta_1 - \beta_{1,\alpha}}{\eta_1} \frac{\beta_{2,\alpha}}{\beta_{2,\alpha} - \beta_{1,\alpha}} e^{-b\beta_{1,\alpha}} 
    + \frac{\beta_{2,\alpha} - \eta_1}{\eta_1} \frac{\beta_{1,\alpha}}{\beta_{2,\alpha} - \beta_{1,\alpha}} e^{-b\beta_{2,\alpha}}
    \]

    \[
    \mathbb{E}[e^{-\alpha\tau_b} \mathbf{1}_{\{X_{\tau_b} - b > y\}}] = e^{-\eta_1 y} \frac{(\eta_1 - \beta_{1,\alpha})(\beta_{2,\alpha} - \eta_1)}{\eta_1 (\beta_{2,\alpha} 
    - \beta_{1,\alpha})} [e^{-b\beta_{1,\alpha}} - e^{-b\beta_{2,\alpha}}] \text{ for all } y \geq 0
    \]

    \[
    \mathbb{E}[e^{-\alpha\tau_b} \mathbf{1}_{\{X_{\tau_b} = b\}}] = \frac{\eta_1 - \beta_{1,\alpha}}{\beta_{2,\alpha} - \beta_{1,\alpha}} e^{-b\beta_{1,\alpha}} +
     \frac{\beta_{2,\alpha} - \eta_1}{\beta_{2,\alpha} - \beta_{1,\alpha}} e^{-b\beta_{2,\alpha}}
    \]
    \par The definition of $\tau_b$ are same and definition of $X$ equilivent to $Z$ here.




    }
    
\end{frame}
\begin{frame}{Proof Con.}

    
    {\footnotesize \footnotesize
    \par Based on the Theorem 3.1, we can get explicit formula of the Laplace transform 
    for $\Psi(\mu, \sigma, \lambda, p, \eta_1, \eta_2; a, b, T)$ (write as $\Psi(a, b, T)$ for simplicity). Define the Laplace transform in \( T \):

    \[
    \Phi_\alpha(a, b) := \int_0^\infty e^{-\alpha T} \Psi(a, b, T)  dT = 
    \int_0^\infty e^{-\alpha T} \mathbb{E}[1_{\{\tau_b \leq T\}} 1_{\{X(T) \geq a\}}]  dT
    \]

    \par  \pause We use Fubini Theorem and strong Markov property can rewrite the formula, then split by overshoot and use tail-integration eventuality
    we will end up with the following:
    {\footnotesize \tiny
    \begin{align*}
        \Phi_\alpha(a,b) &= A_1 e^{-\beta_{1,\alpha}(a-b)} \left( \mathbb{E} \left[ e^{-\alpha\tau_b} \mathbf{1}_{\{X_{\tau_b}=b\}} \right] +
         \beta_{1,\alpha} \int_0^{a-b} e^{\beta_{1,\alpha}y} \mathbb{E} \left[ e^{-\alpha\tau_b} \mathbf{1}_{\{X_{\tau_b}-b>y\}} \right] dy \right) \\
        &\quad + B_1 e^{-\beta_{2,\alpha}(a-b)} \left( \mathbb{E} \left[ e^{-\alpha\tau_b} \mathbf{1}_{\{X_{\tau_b}=b\}} \right]
        + \beta_{2,\alpha} \int_0^{a-b} e^{\beta_{2,\alpha}y} \mathbb{E} \left[ e^{-\alpha\tau_b} \mathbf{1}_{\{X_{\tau_b}-b>y\}} \right] dy \right)
    \end{align*}
    

    }
    \par where:
    {\footnotesize \tiny
    \begin{align*}
        A_1 = \frac{1}{\alpha} \frac{\eta_1 - \beta_{1,\alpha}}{\eta_1} \cdot \frac{\beta_{2,\alpha}}{\beta_{2,\alpha} - \beta_{1,\alpha}}, 
        \quad B_1 = \frac{1}{\alpha} \frac{\beta_{2,\alpha} - \eta_1}{\eta_1} \cdot \frac{\beta_{1,\alpha}}{\beta_{2,\alpha} - \beta_{1,\alpha}}
    \end{align*}
    }
    }
    
\end{frame}

\begin{frame}{Proof Con.}

    
    {\footnotesize \footnotesize
    \par Back to the proof of the Theorem for Barrier option. First rewrite UIC as:
    {\footnotesize \tiny
    \begin{align*}
        UIC & = E^{\mathbb{P}^*}[e^{-rT}(S(T) - K)^+I{\{ \max\limits_{0 \leq t \leq T} S(t) \geq H \}}]\\
        &= \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} S(T) \mathbf{1}_{\{S(T) \geq K, \max_{0 \leq t \leq T} S(t) \geq H\}} \right]\\
        &- Ke^{-rT} \mathbb{P}^* \left[ S(T) \geq K, \max_{0 \leq t \leq T} S(t) \geq H \right]\\
        &= I - Ke^{-rT} \cdot II 
    \end{align*}
    }
    \par  \pause Since the logâ€“price \( X(t) = \log(S(t)/S(0)) \):
    {\footnotesize \tiny
    \begin{align*}
        S(T) \geq K \iff X(T) \geq \log \frac{K}{S(0)},
        \quad \max_{0 \leq t \leq T} S(t) \geq H \iff \max_{0 \leq t \leq T} X(t) \geq \log \frac{H}{S(0)}.
    \end{align*}
    }
    \par Based on the definition of $\Psi(\mu, \sigma, \lambda, p, \eta_1, \eta_2; a, b, T)$:
    {\footnotesize \tiny
    \begin{align*}
        II = \Psi \left( r - \frac{1}{2} \sigma^2 - \lambda \zeta, \sigma, \lambda, p, \eta_1, \eta_2; \log \left( \frac{K}{S(0)} \right), \log \left( \frac{H}{S(0)} \right), T \right)
    \end{align*}
    }
    }
    
\end{frame}

\begin{frame}{Proof Con.}

    
    {\footnotesize \scriptsize
    \par For the first term, we can use a change of numeraire argument. More precisely, introduce a new probability \(\tilde{\mathbb{P}}\) defined as:
     {\footnotesize \tiny
    \begin{align*}
        \frac{d \tilde{\mathbb{P}}}{d \mathbb{P}^*} \bigg|_{t=T} = e^{-rT} \frac{S(T)}{S(0)} = e^{-rT} e^{X(T)} 
    = \exp \left\{ \left( -\frac{1}{2} \sigma^2 - \lambda \zeta \right) T + \sigma W(T) + \sum_{i=1}^{N(T)} Y_i \right\}
    \end{align*}
    }
    \par \pause  Note that this is a well-defined probability as $\mathbb{E}^{\mathbb{P}^*}[e^{-rt}(S(t)/S(0))] = 1$. Then we 
    reparametrize everything we need under  \(\tilde{\mathbb{P}}\). The Brownian part by Girsanov is $\tilde{W}(t) = W(t) - \sigma t$. 
    The diffusion drift shifts by \(+\sigma^2\), $\tilde{\mu} = r + \frac{1}{2}\sigma^2 - \lambda\zeta$. 
    The modified jump rate and the jump distribution: \pause 
    {\footnotesize \tiny
    \begin{align*}
        \text{New rate : } \tilde{\lambda} = \lambda\mathbb{E}^{\mathbb{P}^*}[e^Y] 
        = \lambda(1 + \zeta), \quad \text{where } \zeta = \mathbb{E}^{\mathbb{P}^*}[e^Y] - 1 = \frac{p\eta_1}{\eta_1 - 1} + \frac{q\eta_2}{\eta_2 + 1} - 1
    \end{align*}
    }
    \vspace{-2em}
    {\footnotesize \tiny
    \begin{align*}
        \text{New jump density: }\tilde{f}_Y(y) = \frac{e^y}{\mathbb{E}^{\mathbb{P}^*}[e^Y]} f_Y(y) 
        = \tilde{p}\tilde{\eta}_1 e^{-\tilde{\eta}_1 y}\mathbf{1}_{y\geq 0} + \tilde{q}\tilde{\eta}_2 e^{\tilde{\eta}_2 y}\mathbf{1}_{y<0}
    \end{align*}
    }
     \vspace{-2em}
    {\footnotesize \tiny
    \begin{align*}
        \text{With: } \tilde{\eta}_1 = \eta_1 - 1,\;\tilde{\eta}_2 = \eta_2 + 1,\;\tilde{p} = p\left(\frac{p\eta_1}{\eta_1 - 1}
         + \frac{q\eta_2}{\eta_2 + 1}\right)^{-1} \frac{\eta_1}{\eta_1 - 1},
         \; \tilde{q} = q\left(\frac{p\eta_1}{\eta_1 - 1} + \frac{q\eta_2}{\eta_2 + 1}\right)^{-1} \frac{\eta_2}{\eta_2 + 1}
    \end{align*}
    }
    \par  \pause For I:
    \vspace{-2em}
     {\footnotesize \tiny
    \begin{align*}
        I 
        &= S(0) \mathbb{E}^{\mathbb{P}^*} \left[ e^{-rT} \frac{S(T)}{S(0)} \cdot \mathbf{1}_{\{S(T) \geq K, \max_{0 \leq t \leq T} S(t) \geq H\}} \right]\\
        &= S(0) \tilde{\mathbb{P}} \left[ S(T) \geq K, \min_{0 \leq t \leq T} S(t) \leq H \right]\\
        & = S(0) \Psi \left( r + \frac{1}{2} \sigma^2 - \lambda \zeta, \sigma, \tilde{\lambda}, \tilde{p}, \tilde{\eta}_1, \tilde{\eta}_2; \log \left( \frac{K}{S(0)} \right), \log \left( \frac{H}{S(0)} \right), T \right)
    \end{align*}
    }

    }
    
\end{frame}

 \section{Part II}
\begin{frame}{Part II}

    \begin{center}
        Pricing Path-Dependent Options with Jump Risk via Laplace Transforms
    \end{center}
    \vspace{2em}
    \begin{center}
        Steven Kou\\
        Giovanni Petrella\\
        Hui Wang
    \end{center}
    \vspace{3em}
    \par  Derive the Laplace transforms for 
    casepricing of European call and put options. Derive the two dimensional Laplace transform for barrier option.

\end{frame}



\begin{frame}{European call and put options}

    {\footnotesize \footnotesize
    \par The price of a European call and put with maturity \( T \) and strike \( K \), is given:
    
    \begin{align*}
        C_T(k) &= e^{-rT} \mathbb{E}^{\mathbb{P}^*} [(S(T) - K)^+] = e^{-rT} \mathbb{E}^{\mathbb{P}^*} \left[ (S(0)e^{X(T)} - e^{-k})^+ \right]\\
        P_T(k')& = e^{-rT} \mathbb{E}^{\mathbb{P}^*} [(K - S(T))^+] = e^{-rT} \mathbb{E}^{\mathbb{P}^*} \left[ (e^{k'} - S(0)e^{X(T)})^+ \right]
    \end{align*}
    
    \par  \pause By the change of numeraire argument w.r.t $S(t)$:
    
    \begin{align*}
       C_T(k) &= S(0) \tilde{\Psi}_C(k) - e^{-k} e^{-rT} \Psi_C(k)\\
        P_T(k') &= e^{k'} e^{-rT} \Psi_P(k') - S(0) \tilde{\Psi}_P(k')\\
    \end{align*}
    
    \vspace{-2em}
    \par where: 
    \begin{align*}
      \Psi_C(k) &= \mathbb{P}^*(S(T) \geq e^{-k}),\;\tilde{\Psi}_C(k) = \tilde{\mathbb{P}}(S(T) \geq e^{-k})\\
      \Psi_P(k') &= \mathbb{P}^*(S(T) < e^{k'}), \; \tilde{\Psi}_P(k') = \tilde{\mathbb{P}}(S(T) < e^{k'})
    \end{align*}
    }
    
\end{frame}

\begin{frame}{European call and put options Con.}

    {\footnotesize \footnotesize
    \par Lemma. The Laplace transform with respect to \( k \) of \( C_T(k) \) and with respect to \( k' \) for 
    the put option \( P_T(k') \) are given by:
    \begin{align*}
        \tilde{f}_C(\xi) &:= \int_{-\infty}^{\infty} e^{-\xi k} C_T(k)  dk 
        = e^{-rT} \frac{S(0)^{\xi+1}}{\xi(\xi+1)} \exp(G(\xi+1)T), \quad \xi > 0\\
        \tilde{f}_P(\xi) &:= \int_{-\infty}^{\infty} e^{-\xi k'} P_T(k')  dk' 
        = e^{-rT} \frac{S(0)^{-\xi-1}}{\xi(\xi-1)} \exp(G(-(\xi-1))T), \quad \xi > 1
    \end{align*}
    \par  \pause The Laplace transforms with respect to \( k \)  of \( \Psi_C(k) \) and \( k' \) of \( \Psi_P(k') \) are:
    \begin{align*}
        \tilde{f}_{\Psi_C}(\xi) &:= \int_{-\infty}^{\infty} e^{-\xi k} \Psi_C(k)  dk = \frac{S(0)^{\xi}}{\xi} \exp(G(\xi)T), \quad \xi > 0\\
        \tilde{f}_{\Psi_P}(\xi) &:= \int_{-\infty}^{\infty} e^{-\xi k'} \Psi_P(k')  dk' = e^{-rT} \frac{S(0)^{-\xi}}{\xi} \exp(G(-\xi)T), \quad \xi > 0
    \end{align*}
    }
    
\end{frame}


\begin{frame}{European call and put options Con.}

    {\footnotesize \scriptsize
    \par Proof:
    \par The Laplace transform for the call option is:
    \begin{align*}
        \hat{f}_C(\xi) = e^{-rT} \int_{-\infty}^{\infty} e^{-\xi k} \mathbb{E}^{\mathbb{P}^*} \left[ (S(0)e^{X(T)} - e^{-k})^+ \right]  dk
    \end{align*}
    \par  \pause Applying the Fubini theorem yields for every \(\xi > 0\):
    \begin{align*}
        \hat{f}_C(\xi) &= e^{-rT} \mathbb{E}^{\mathbb{P}^*} \left[ \int_{-\infty}^{\infty} e^{-\xi k} \left( S(0)e^{X(T)} - e^{-k} \right)^+  dk \right]\\
        &= e^{-rT} \mathbb{E}^{\mathbb{P}^*} \left[ \int_{-X(T)-\log S(0)}^{\infty} e^{-\xi k} \left( S(0)e^{X(T)} - e^{-k} \right)  dk \right]\\
        &= e^{-rT} \mathbb{E}^{\mathbb{P}^*} \left[ S(0)e^{X(T)} e^{\xi (X(T)+\log S(0))} \frac{1}{\xi} - e^{(\xi+1)(X(T)+\log S(0))} \frac{1}{\xi+1} \right]\\
        &= e^{-rT} \frac{S(0)^{\xi+1}}{\xi (\xi+1)} \mathbb{E}^{\mathbb{P}^*} \left[ e^{(\xi+1)X(T)} \right] \overset{\text{MGF}}{=}
          e^{-rT} \frac{S(0)^{\xi+1}}{\xi (\xi+1)} e^{G(\xi+1)T}
    \end{align*}
    
    \par Similary, we can get the  Laplace transform for the put option. 
    }
    
\end{frame}
\begin{frame}{European call and put options Con.}

    {\footnotesize \footnotesize
    \par  The Laplace transforms with respect to \( k \) of \( \Psi_C(k) \):
    \begin{align*}
        \hat{f}_{\Psi_C}(\xi) &= \int_{-\infty}^{\infty} e^{-\xi k} \mathbb{E}^ {\mathbb{P}^*} \left[ \mathbf{1}_{\{S(T) \geq e^{-k}\}} \right]  dk \\
       &  = \int_{-\infty}^{\infty} e^{-\xi k} \mathbb{E}^{\mathbb{P}^*} \left[ \mathbf{1}_{\{k \geq -\log S(T)\}} \right]  dk\\
       & =\mathbb{E}^{\mathbb{P}^*} \left[ \int_{-\log S(T)}^{\infty} e^{-\xi k}  dk \right] \\
       &= \frac{1}{\xi} \mathbb{E}^{\mathbb{P}^*} \left[ S(T)^{\xi} \right] = 
       \frac{S(0)^{\xi}}{\xi} \mathbb{E}^{\mathbb{P}^*} \left[ e^{\xi X(T)} \right] \overset{\text{MGF}}{=} \frac{S(0)^{\xi}}{\xi} e^{G(\xi)T}
    \end{align*}
    \par Similary, we can get the  Laplace transform for $\Psi_P(k')$. 
    }
    
\end{frame}
\begin{frame}{Barrier Options}

    {\footnotesize \footnotesize
    \par Rewrite the pricing formula of up-and-in call option(UIC) in early silde:
     \pause 
    \begin{align*}
        UIC(k,T) = E^{\mathbb{P}^*} \left[ e^{-rT} \left( S(T) - e^{-k} \right)^+ I{[\tau_b < T]} \right]
    \end{align*}
    \par where \( H > S(0) \) is the barrier level, \( k = -\log(K) \) the transformed strike and \( b = \log(H/S(0)) \). In previous paper, we obtain:
    \begin{align*}
        UIC(k,T) = S(0) \tilde{\Psi}_{UI}(k,T) - Ke^{-rT} \Psi_{UI}(k,T)
    \end{align*}
    \par where:
    \begin{align*}
        \Psi_{UI}(k,T) = P^*(S(T) \geq e^{-k},  \tau_b < T), \quad \widetilde{\Psi}_{UI}(k,T) = \widetilde{P}(S(T) \geq e^{-k},  \tau_b < T) 
    \end{align*}
    % \par Remark: Here we will relies on a two-dimensional Laplace transform for botth the option price and the probabilities. The formulae after doing two-dimensional 
    % transforms become much simpler than the one-dimensional formulae in Kou and Wang (2003), which involve many special functions.
    }
    
\end{frame}


\begin{frame}{Barrier Options Con.}

    {\footnotesize \footnotesize
    \par Theorem:  For \(\xi\) and \(\alpha\) such that \(0 < \xi < \eta_1 - 1\) and \(\alpha > \max(G(\xi + 1) - r, 0)\) (such a choice of \(\xi\) and \(\alpha\) is possible 
    for all small enough \(\xi\) as \(G(1) - r = -\delta < 0\)). The Laplace transform with respect to \(k\) and \(T\) of \(UIC(k, T)\) is given by
    \begin{align*}
    \tilde{f}_{UIC}(\xi, \alpha) &= \int_{0}^{\infty} \int_{-\infty}^{\infty} e^{-\xi k - \alpha T} UIC(k, T) dk dT \\
    &= \frac{H^{\xi+1}}{\xi (\xi + 1)} \frac{1}{r + \alpha - G(\xi + 1)} \left( A(r + \alpha) \frac{\eta_1}{\eta_1 - (\xi + 1)} + B(r + \alpha) \right)
    \end{align*}
    \par  \pause where

    \begin{align*}
    A(h) &:= E^{\mathbb{P}^*} \left[ e^{-h\tau_b} \mathbf{1}_{\{X(\tau_b) > b\}} \right] =
     \frac{(\eta_1 - \beta_{1,h}) (\beta_{2,h} - \eta_1)}{\eta_1 (\beta_{2,h} - \beta_{1,h})} \left[ e^{-b\beta_{1,h}} - e^{-b\beta_{2,h}} \right]\\
    B(h) &:= E^{\mathbb{P}^*} \left[ e^{-h\tau_b} \mathbf{1}_{\{X(\tau_b = b)\}} \right] =
    \frac{\eta_1 - \beta_{1,h}}{\beta_{2,h} - \beta_{1,h}} e^{-b\beta_{1,h}} + \frac{\beta_{2,h} - \eta_1}{\beta_{2,h} - \beta_{1,h}} e^{-b\beta_{2,h}}
    \end{align*}
    \par with \(b = \log(H/S(0))\).
    }
    


\end{frame}

\begin{frame}{Barrier Options Con.}

    {\footnotesize \footnotesize
    \par  If \(0 < \xi < \eta_1\) and \(\alpha > \max(G(\xi), 0)\) (again this choice of \(\xi\) and \(\alpha\) is possible for 
    all \(\xi\) small enough as \(G(0) = 0\)), then the Laplace transform with respect to \(k\) and \(T\) of \(\Psi_{UI}(k, T)\) is:
     \vspace{1em}
    \begin{align*}
        \tilde{f}_{\Psi_{UI}}(\xi, \alpha) &= \int_0^{\infty} \left( \int_{-\infty}^{\infty} e^{-\xi k - \alpha T} \Psi_{UI}(k, T) dk \right) dT\\
    &= \frac{H^{\xi}}{\xi} \frac{1}{\alpha - G(\xi)} \left( A(\alpha) \frac{\eta_1}{\eta_1 - \xi} + B(\alpha) \right)
    \end{align*}

    \vspace{1em}
    \par  \pause The Laplace transforms with respect to \(k\) and \(T\) of \(\tilde{\Psi}_{UI}(k, T)\) is given 
    similarly with \(\tilde{G}\) replacing \(G\) and the functions \(\tilde{A}\) and \(\tilde{B}\) defined similarly. 
    % To perform the inversion, They use the two-sided Euler method(EUL) as in Petrella (2004). Compare with GS method, EUL use standard double
    %  precision, get stable answers, and convergence is much faster.
    }
\end{frame}

\begin{frame}{Barrier Options Con.}

    {\footnotesize \scriptsize
    \par Proof: Follow the pricing formula of UIC and the Fubini theorem:
    \begin{align*}
        \tilde{f}_{UIC}(\xi, \alpha) &= \int_{0}^{\infty} \int_{-\infty}^{\infty} e^{-\xi k - (r + \alpha) T}
         \mathbb{E}^{\mathbb{P}^*} \left[ \left( S(T) - e^{-k} \right)^+ \mathbf{1}_{\{\tau_b < T\}} \right] dkdT\\
        & = \mathbb{E}^{\mathbb{P}^*} \left[ \int_{0}^{\infty} e^{-(r + \alpha) T} \mathbf{1}_{\{\tau_b < T\}}
          \left( \int_{-\log S(T)}^{\infty} e^{-\xi k} \left( S(T) - e^{-k} \right) dk \right) dT \right]\\
          &= \frac{1}{\xi (\xi + 1)} \mathbb{E}^{\mathbb{P}^*} \left[ \int_{0}^{\infty} e^{-(r + \alpha) T} \mathbf{1}_{\{\tau_b < T\}} S(T)^{\xi + 1} dT \right] \\
          {\footnotesize \tiny(\text{$T = \tau_b + t$ with $t>0$})} &=\frac{1}{\xi (\xi + 1)} \mathbb{E}^{\mathbb{P}^*} \left[ e^{-(r + \alpha) \tau_b} \int_{0}^{\infty} e^{-(r + \alpha) t} S(t + \tau_b)^{\xi + 1} 
          dt \right]\\
          &=\frac{1}{\xi (\xi + 1)} \mathbb{E}^{\mathbb{P}^*} \left[ e^{-(r + \alpha) \tau_b} 
            \mathbb{E}^ {\mathbb{P}^*} \left[ \int_{0}^{\infty} e^{-(r + \alpha) t} S(t + \tau_b)^{\xi + 1} dt \middle| \mathcal{F}_{\tau_b} \right] 
           \right]\\
           {\footnotesize \tiny(\text{$i$})}&=\frac{1}{\xi (\xi + 1)} \mathbb{E}^{\mathbb{P}^*} \left[ e^{-(r + \alpha) \tau_b} 
            S(\tau_b)^{\xi+1} \int_0^\infty e^{-(r+\alpha)t} \mathbb{E}^{\mathbb{P}^*} \left[ e^{(\xi+1)X(t)} \right]  dt 
           \right]\\
    \end{align*}
    \vspace{-2em}
    \par Where $i$ is based on $S(\tau_b + t)^{\xi+1} = \left(S(\tau_b)\right)^{\xi+1} \cdot e^{(\xi+1)(X(\tau_b + t) - X(\tau_b))}$ and 
    strong Markov property that $\mathbb{E}^{\mathbb{P}^*} \left[ e^{(\xi+1)(X(\tau_b + t) - X(\tau_b))} \middle| \mathcal{F}_{\tau_b} \right] 
    = \mathbb{E}^{\mathbb{P}^*} \left[ e^{(\xi+1)X(t)} \right]$
    
    }
\end{frame}
\begin{frame}{Barrier Options Con.}

    {\footnotesize \scriptsize
    \par Con.
    \begin{align*}
         {\footnotesize \tiny(\text{MGF})}  &=\frac{1}{\xi (\xi + 1)} \mathbb{E}^{\mathbb{P}^*} \left[ e^{-(r + \alpha) \tau_b} 
            S(\tau_b)^{\xi+1} \int_0^\infty e^{-(r+\alpha)t} e^{G(\xi+1)t} dt 
           \right]\\
        & = \frac{1}{\xi(\xi+1)} \frac{1}{r + \alpha - G(\xi+1)} \mathbb{E}^{\mathbb{P}^*} \left[ e^{-(r+\alpha) \tau_b} S(\tau_b)^{\xi+1} \right]\\
        &= \frac{1}{\xi(\xi+1)} \frac{1}{r + \alpha - G(\xi+1)} \left\{\mathbb{E}^{\mathbb{P}^*} \left[ e^{-(r+\alpha) \tau_b} H^{\xi+1} \mathbf{1}_{\{X(\tau_b)>b\}} \right] 
        \mathbb{E}^{\mathbb{P}^*} \left[ e^{(\xi+1)\chi^+} \right]\right. \\
        & +\left. \mathbb{E}^{\mathbb{P}^*} \left[ e^{-(r+\alpha) \tau_b} H^{\xi+1} \mathbf{1}_{\{X(\tau_b)=b\}} \right] \right\}\\
        & = \frac{H^{\xi+1}}{\xi(\xi+1)} \frac{1}{r + \alpha - G(\xi+1)} 
        \left\{ A(r + \alpha) \frac{\eta_1}{\eta_1 - (\xi+1)} + B(r + \alpha) \right\}
    \end{align*}
    \par \pause  Where \( \chi^+ \sim \text{Exp}(\eta_1) \), and $A(h) := \mathbb{E}^{\mathbb{P}^*} [e^{-h\tau_b} \mathbf{1}_{\{X(\tau_b) > b\}}],  B(h) := \mathbb{E}^{\mathbb{P}^*} [e^{-h\tau_b} \mathbf{1}_{\{X(\tau_b) = b\}}].$
    \par \( A(h) \) and \( B(h) \) explicitly (via first-passage Laplace transforms) with \(\beta_{1,h}, \beta_{2,h}\) being the two positive roots of \( G(\beta) = h\):
        \[
        A(h) = \frac{(\eta_1 - \beta_{1,h})(\beta_{2,h} - \eta_1)}{\eta_1 (\beta_{2,h} - \beta_{1,h})} \left( e^{-b\beta_{1,h}} - e^{-b\beta_{2,h}} \right)
        \]
        \[
        B(h) = \frac{\eta_1 - \beta_{1,h}}{\beta_{2,h} - \beta_{1,h}} e^{-b\beta_{1,h}} + \frac{\beta_{2,h} - \eta_1}{\beta_{2,h} - \beta_{1,h}} e^{-b\beta_{2,h}}
        \]
    }
\end{frame}
\begin{frame}{Barrier Options Con.}

    {\footnotesize \scriptsize
    \par For the Laplace transform of the probability \(\Psi_{UI}\), apply the same trick we have: 
    \begin{align*}
        \hat{f}_{\Psi_{UI}}(\xi, \alpha) &= \int_0^\infty \left[ \int_{-\infty}^\infty e^{-\xi k - \alpha T} \cdot
         \mathbb{E}^{\mathbb{P}^*} \left\{ \mathbf{1}_{\{k > -\log(S(T)), \tau_b < T\}} \right\}  dk \right] dT\\
        &= \mathbb{E}^{\mathbb{P}^*} \left\{ \int_{\tau_b}^\infty \left[ \int_{-\log S(T)}^\infty e^{-\xi k - \alpha T}  dk \right] dT \right\}\\
        &= \frac{1}{\xi} \mathbb{E}^{\mathbb{P}^*} \left\{ \int_{\tau_b}^\infty S(T)^{\xi} e^{-\alpha T} dT \right\}\\
        &= \frac{1}{\xi} \mathbb{E}^{\mathbb{P}^*} \left\{ e^{-\alpha \tau_b} \int_0^\infty \{ S(t + \tau_b) \}^{\xi} e^{-\alpha t} dt \right\}\\
        &= \frac{1}{\xi} \mathbb{E}^{\mathbb{P}^*} \left\{ e^{-\alpha \tau_b} \mathbb{E}^{\mathbb{P}^*} \left[ \int_0^\infty S(\tau_b + t)^\xi e^{-\alpha t} 
         dt \middle| \mathcal{F}_{\tau_b} \right]\right\}\\
         & =\frac{1}{\xi} \frac{1}{\alpha - G(\xi)} \mathbb{E}^{\mathbb{P}^*} \left\{ e^{-\alpha \tau_b} [S(\tau_b)]^{\xi} \right\}\\
         & =  \frac{1}{\xi} \frac{1}{\alpha - G(\xi)} \left\{ \mathbb{E}^{\mathbb{P}^*} \left[ e^{-\alpha \tau_b} H^{\xi} \mathbf{1}_{[X(\tau_b) > b]} \right] \mathbb{E}^{\mathbb{P}^*} \left[ e^{\xi \chi^+} \right] 
         + \mathbb{E}^{\mathbb{P}^*} \left[ e^{-\alpha \tau_b} H^{\xi} \mathbf{1}_{[X(\tau_b) = b]} \right] \right\}\\
         &= \frac{H^{\xi}}{\xi} \frac{1}{\alpha - G(\xi)} \left\{ A(\alpha) \frac{\eta_1}{\eta_1 - \xi} + B(\alpha) \right\}
    \end{align*}
    }
\end{frame}


 \section{Part III}
\begin{frame}{Part III}

    \begin{center}
        A Two-Sided Laplace inversion Algorithm \\
       With Computable Error Bounds And Its \\
       Applications In Financial Engineering
    \end{center}
    \vspace{2em}
    \begin{center}
        Ning Cai\\
        Steven Kou\\
        ZongJian Liu
    \end{center}
    \vspace{3em}
    \par  Derive the Laplace transforms for 
    casepricing of European call and put options. Derive the two dimensional Laplace transform for barrier option.

\end{frame}

\begin{frame}{Two-sided Laplace Transform}


    {\footnotesize \footnotesize
    \par For a function \( f(t) \) defined on the whole real line \((-\infty, \infty)\), its two-sided Laplace transform is:
    \begin{align*}
        L_f(s) = \int_{-\infty}^{\infty} e^{-st}f(t)\,dt
    \end{align*}
    \par  \pause  Where \( s = \sigma + i\omega \) is a complex variable. The region of absolute convergence (ROAC) is the set of $s$ such that:
    \begin{align*}
        \int_{-\infty}^{\infty} e^{-\sigma t}|f(t)|\,dt < \infty
    \end{align*}
    \par   \pause Define: 
    \begin{align*}
         \sigma_l = \inf \left\{ \sigma \in \mathbb{R} : \int_{-\infty}^{\infty} e^{-\sigma t}|f(t)|\,dt < \infty \right\}\;\;
          \sigma_u = \sup \left\{ \sigma \in \mathbb{R} : \int_{-\infty}^{\infty} e^{-\sigma t}|f(t)|\,dt < \infty \right\}
    \end{align*}
    \par Then the ROAC is the strip \((\sigma_l, \sigma_u)\) in the complex plane (independent of the imaginary part \(\omega\)).
    }
    
\end{frame}

\begin{frame}{Ambiguity of inversion}


    {\footnotesize \footnotesize
    It is worth pointing out that the same 
    two-sided Laplace transforms with different ROACs may correspond to different original functions; for example, consider three functions:
    \vspace{1em}
    \begin{align*}
        f_1(t) =
        \begin{cases} 
        e^{2t} - e^{-3t}, & t \geq 0\\
        0, & t < 0
        \end{cases}\;\;f_2(t) =
        \begin{cases} 
        -e^{-3t}, & t \geq 0\\
        -e^{2t}, & t < 0
        \end{cases}\;\;f_3(t) =
        \begin{cases} 
        0, & t \geq 0\\
        e^{-3t} - e^{2t}, & t < 0
        \end{cases}
    \end{align*}
    \vspace{1em}
    \par \pause  Laplace transforms are all \( L(s) = 5/(s^2 + s - 6) \) 
    but with different ROACs: \((2, +\infty)\), \((-3, 2)\), and \((-\infty, -3)\), respectively. 
    Consequently, when inverting a two-sided Laplace transform \( L_f(s) \), we should first specify a particular ROAC.  Moreover, the examples 
    imply that the ROAC of a two-sided Laplace transform may not include the imaginary axis \(\{s : \text{Re}(s) = 0\}\).
    \vspace{1em}
    % \par Moreover, the example shows the same \( L(s) \) could correspond to 
    % functions where the Fourier transform is well defined (\( f_2 \)) or not well defined (\( f_1, f_3 \)). The ROAC might not cross the imaginary axis, 
    % which means the Fourier transform may fail to exist even though the Laplace transform is perfectly valid.
    }
    
\end{frame}

\begin{frame}{One-sided Laplace transforms and Fourier transforms}


    {\footnotesize \footnotesize
    If \( f(t) = 0 \) for any \( t < 0 \) then its two-sided Laplace transform is reduced to:
    \begin{align*}
        L_f(s) = \int_{0}^{+\infty} e^{-st}f(t)  dt \quad \text{for Re}(s) \in \text{ROAC}
    \end{align*}

    \par and we call it the one-sided Laplace transform. The Fourier transform \emph{\( \mathcal{F}_f(\omega) : \mathbb{R} \mapsto \mathbb{C} \)} of the function \( f(t) \) is defined by

\[
\mathcal{F}_f(\omega) := \int_{-\infty}^{\infty} e^{-i\omega t}f(t)  dt \equiv L_f(i\omega) \quad \text{for any } \omega \in \mathbb{R}.
\]

\par  \pause Because the ROAC of a two-sided Laplace transform may not include the imaginary axis \(\{s : \text{Re}(s) = 0\}\), the Fourier
 transform of a function may not exist. For example, the Fourier transforms of \( f_1(t) \) and \( f_3(t) \) in the example do not exist,
  whereas their 
two-sided Laplace transforms are well defined. Therefore, the Fourier transform is a special case of the two-sided Laplace transform.
    }
    
\end{frame}

\begin{frame}{The Two-sided Laplace inversion formula}


    {\footnotesize \footnotesize
    \par We want to invert the two-sided Laplace transform:
    \begin{align*}
        L_f(s) = \int_{-\infty}^{\infty} e^{-st}f(t)  dt
    \end{align*}
    \par to recover \( f(t) \). The challenge is the inversion involves infinite integrals. We must approximate them. 
    That's where discretization and truncation errors come in. Our two-sided Laplace inversion formula involves 
    parameters \( C \) and \( N \) for the purpose of controlling the discretization and truncation errors, respectively.
    \vspace{1em}
    \par  \pause \textbf{Assumption}: The function \( e^{-\sigma t} f(t) \) is of bounded variation on \( \mathbb{R} \) for any \( \sigma \in \text{ROAC} \).
    \par This ensures the inversion formula is well-defined and stable. Recall a real-valued function \( g : [a, b] \to \mathbb{R} \) is said to be of bounded variation if the total variation:
    \begin{align*}
        V_a^b(g) := \sup \left\{ \sum_{i=1}^n |g(x_i) - g(x_{i-1})| : a = x_0 < x_1 < \cdots < x_n = b \right\}
    \end{align*}
    \par is finite.
    }
    
\end{frame}

\begin{frame}{The Two-sided Laplace inversion formula}


    {\footnotesize \scriptsize
    \par \textbf{Theorem}: Consider a function \( f(t) \) normalized such that \( 2f(t) = f(t + 0) + f(t - 0) \) 
    for any real \( t \), where \( f(t \pm 0) := \lim_{\varepsilon \downarrow 0} f(t \pm \varepsilon) \). 
    Then, under assumption, for any \( t \) and \( \sigma \in \text{ROAC} \),
    \begin{align*}
        f(t) = f_A(t, \sigma, C, N) + e_T(t, \sigma, C, N) - e_D(t, \sigma, C)
    \end{align*}
    \par where the output of the inversion algorithm is:
    {\footnotesize \tiny
    \begin{align*}
        f_A(t, \sigma, C, N) := \frac{e^{\sigma t} L_f(\sigma)}{2(|t| + C)} + \frac{e^{\sigma t}}{|t| + C} 
        \sum_{k=1}^{N} \left[ (-1)^k \text{Re} \left( \exp \left\{ -\frac{\text{sgn}(t)C k \pi i}{t 
        + \text{sgn}(t)C} \right\} \times L_f \left( \sigma + \frac{k \pi i}{t + \text{sgn}(t)C} \right) \right) \right]
        % f_A(t, \sigma, C, N) := \frac{e^{\sigma t} L_f(\sigma)}{2(|t| + C)} &+ \frac{e^{\sigma t}}{|t| + C} 
        % \sum_{k=1}^{N} \left[ (-1)^k \text{Re} \left( \exp \left\{ -\frac{\text{sgn}(t)C k \pi i}{t 
        % + \text{sgn}(t)C} \right\}\right.\right.\\&\left.\left.\times L_f \left( \sigma + \frac{k \pi i}{t + \text{sgn}(t)C} \right) \right) \right]
    \end{align*}
    }
    \par  \pause \( C \geq 0 \) is a constant such that \( |t| + C \neq 0 \), \( N > 0 \) is a positive integer, and \(\text{sgn}(x)\) equals \( 1 \) if \( x \geq 0 \) and equals \(-1\) otherwise.
     The terms \( e_T(t, \sigma, C, N) \) and \( e_D(t, \sigma, C) \) represent the truncation error and the discretization error, respectively:
     {\footnotesize \tiny
    \begin{align*}
       e_T(t, \sigma, C, N) := \frac{e^{\sigma t}}{|t| + C} 
       \sum_{k=N+1}^{+\infty} \left[ (-1)^k \text{Re} \left( \exp \left\{ -\frac{\text{sgn}(t)C k \pi i}{t + \text{sgn}(t)C} \right\} 
       \times L_f \left( \sigma + \frac{k \pi i}{t + \text{sgn}(t)C} \right) \right) \right]    
    \end{align*}
    }
    \par and 
     {\footnotesize \tiny
    \begin{align*}
      e_D(t, \sigma, C) := \sum_{\substack{k=-\infty \; k \neq 0}}^{+\infty} e^{-2\sigma k (t + \text{sgn}(t)C)} f(2k(t + \text{sgn}(t)C) + t)
    \end{align*}
    }
    }
    
\end{frame}

\begin{frame}{The Two-sided Laplace inversion formula}


    {\footnotesize \scriptsize
    \par Proof:  It suffices to show that, for any \( t \neq 0 \) and \(\sigma \in \text{ROAC}\):
    \begin{align*}
        f(t) = \frac{e^{\sigma t} L_f(\sigma)}{2|t|} + \frac{e^{\sigma t}}{|t|} 
\sum_{k=1}^{\infty} (-1)^k \text{Re} \left( L_f \left( \sigma + \frac{k\pi i}{t} \right) \right) 
- \sum_{\substack{k=-\infty\; k\neq 0}}^{+\infty} e^{-2\sigma kt} f((2k+1)t)
    \end{align*}
    \par  Indeed, to evaluate \( f(t) \), we can alternatively apply above equation to the function \( g_+(y) := f(y - C) \) at 
    the point \( t + C \) if \( t \geq 0 \) or 
    to the function \( g_-(y) := f(y + C) \) at the point \( t - C \) if \( t < 0 \). This give theorem immediately. The reason why shift wich $C$ 
    is the denominator $|t|+C$ in the theorem stabilizes the formula (avoids singularity at t=0).
    \par  \pause Now we prove above equation. Because \(\sigma \in \text{ROAC}\), substituting \(\sigma + i\omega\) for \( s \) in 
    the Bromwich contour integral:
    \vspace{-1em}
    \begin{align*}
        f(t) = \frac{1}{2\pi i} \lim_{T \to +\infty} \int_{\sigma-iT}^{\sigma+iT} e^{ts} L_f(s)  ds
    \end{align*}
    \par \pause  By Euler's formula we obtain:
    \begin{align*}
         f(t) & =\frac{e^{\sigma t}}{2\pi} \lim_{T \to +\infty}
          \int_{T}^{-T} [\cos(\omega t) + i \sin(\omega t)] L_f(\sigma + i\omega)  d\omega\\
          &=\frac{e^{\sigma t}}{2\pi} \int_{0}^{+\infty} \{[\cos(\omega t) 
          + i \sin(\omega t)] L_f(\sigma + i\omega) + [\cos(\omega t) - i \sin(\omega t)] L_f(\sigma - i\omega)\}  d\omega\\
          & = \frac{e^{\sigma t}}{\pi} \int_{0}^{+\infty} [\cos(\omega t) \text{Re}(L_f(\sigma + i\omega)) 
          + \sin(\omega t) \text{Im}(L_f(\sigma - i\omega))]  d\omega
    \end{align*}
    }
    
\end{frame}


\begin{frame}{The Two-sided Laplace inversion formula}


    {\footnotesize \scriptsize
    \par Con.
    \par where the last equality holds because \( \text{Re}(L_f(\sigma + i\omega)) 
    = \text{Re}(L_f(\sigma - i\omega)) \) and \( \text{Im}(L_f(\sigma + i\omega)) = -\text{Im}(L_f(\sigma - i\omega)) \). 
    By the trapezoidal rule, for \( h > 0 \), we define \(\tilde{f}(t)\) as
    \begin{align*}
        \tilde{f}(t) := \frac{he^{\sigma t}}{2\pi} L_f(\sigma) + \frac{he^{\sigma t}}{\pi} \sum_{k=1}^{+\infty} 
        \cos(kht) \operatorname{Re}(L_f(\sigma + ikh)) 
        + \frac{he^{\sigma t}}{\pi} \sum_{k=1}^{+\infty} \sin(kht) \operatorname{Im}(L_f(\sigma - ikh))
    \end{align*}
    \par  \pause Because \( t \neq 0 \), letting \( h = \pi / |t| \) yields:
    \begin{align*}
        \tilde{f}(t) = \frac{e^{\sigma t} L_f(\sigma)}{2|t|} + 
        \frac{e^{\sigma t}}{|t|} \sum_{k=1}^{\infty} (-1)^k \operatorname{Re} \left( L_f \left( \sigma + \frac{k\pi i}{t} \right) \right)
    \end{align*}
    \textbf{The trapezoidal rule}: The trapezoidal rule approximates an integral $\int_{0}^{\infty} g(\omega)  d\omega$ 
    by sampling \( g \) at equally spaced points, $\frac{h}{2} g(0) + h \sum_{k=1}^{\infty} g(kh).$  
    \par \pause  To analyze the discretization error \(\tilde{f}(t) - f(t)\) generated by
     the trapezoidal rule, we define \( g(x) := e^{-\sigma x} f(x) \) for any fixed \(\sigma \in \operatorname{ROAC}\). 
     Under the condition of Theorem, \( g(x) \) is absolutely integrable over \(\mathbb{R}\), is of bounded variation on \(\mathbb{R}\), 
     and satisfies \( 2g(x) = g(x+0) + g(x-0) \) for any \( x \).
      Then, for any fixed \( t \neq 0 \), \( g^*(x) := g(t + x/h) = g(t + |t| x/\pi) \) also has these three properties. 
    }
    
\end{frame}
\begin{frame}{The Two-sided Laplace inversion formula}


    {\footnotesize \scriptsize
    \par Con.
    \par Applying the Poisson summation formula to \( g^*(x) \):
    \begin{align*}
        \sum_{k=-\infty}^{+\infty} g^*(2\pi k) = \frac{1}{2\pi} \sum_{k=-\infty}^{+\infty} \int_{-\infty}^{+\infty} g^*(z)e^{-ikz} dz
    \end{align*}
    \par  \pause \textbf{Poisson summation formula}: For a "nice" function \( g(x) \) (say, integrable and smooth enough), 
    the Poisson summation formula says:
    \begin{align*}
        \sum_{k=-\infty}^{\infty} g(k) = \sum_{m=-\infty}^{\infty} \hat{g}(2\pi m)
    \end{align*}
    \par Where \(\hat{g}(\xi)\) is the Fourier transform of \( g(x)\), $\hat{g}(\xi) = \int_{-\infty}^{\infty} g(x) e^{-i\xi x} dx.$  
    The left-hand side is a sum of the function's samples at the integers.  
    The right-hand side is a sum of its Fourier transform sampled at multiples of \( 2\pi \).
    }
    
\end{frame}
\begin{frame}{The Two-sided Laplace inversion formula}


    {\footnotesize \scriptsize
    \par Con.
    \par The left-hand side:
    \begin{align*}
        g^*(2\pi k) & = \sum_{k=-\infty}^{+\infty} g(t + 2|t|k) \\
        \left(\text{$t<0$, reindex $k \rightarrow -k$}\right)&= \sum_{k=-\infty}^{+\infty} g((2k + 1)t)\\
        \left(\text{Recall \( g(x) := e^{-\sigma x} f(x) \)}\right)&=\sum_{k=-\infty}^{+\infty} e^{-\sigma(2k+1)t} f((2k + 1)t)\\
        & = e^{-\sigma t} \left[ f(t) + \sum_{\substack{k=-\infty \\ k\neq 0}}^{+\infty} e^{-2\sigma kt} f((2k + 1)t) \right]
    \end{align*}
    }
    
\end{frame}
\begin{frame}{The Two-sided Laplace inversion formula}


    {\footnotesize \scriptsize
    \par Con.
    \par The right-hand side:
    \begin{align*}
       \frac{1}{2\pi} \sum_{k=-\infty}^{+\infty} \int_{-\infty}^{+\infty} g^*(z)e^{-ikz} dz &= 
       \frac{1}{2\pi} \sum_{k=-\infty}^{+\infty} \int_{-\infty}^{+\infty} g\left( t + \frac{|t|z}{\pi} \right) e^{-ikz} dz\\
       \left(y = t+\frac{|t|}{\pi}z\right)&= \frac{1}{2|t|} \sum_{k=-\infty}^{+\infty} \left[ \left( \int_{-\infty}^{+\infty} g(y)e^{-ik\pi y/|t|} dy \right) e^{ik\pi t/|t|} \right]\\
       \left( L_f(s) = \int_{-\infty}^{\infty} e^{-st}f(t)  dt\right)& = \frac{1}{2|t|} \sum_{k=-\infty}^{+\infty} L_f \left( \sigma + \frac{ik\pi}{|t|} \right) e^{ik\pi t/|t|}\\
       & = \frac{1}{2|t|} \sum_{k=-\infty}^{+\infty} (-1)^k L_f \left( \sigma + \frac{ik\pi}{t} \right)\\
       & = \frac{1}{2|t|} L_f(\sigma) + \frac{1}{|t|} \sum_{k=1}^{+\infty} (-1)^k \text{Re} \left( L_f \left( \sigma + \frac{ik\pi}{t} \right) \right)
    \end{align*}
    \par \pause  The last step, separate the $k=0$ term and use conjugate 
    symmetry, for real \( f \), \( L_f(\sigma - i\alpha) = \overline{L_f(\sigma + i\alpha)} \). Link the formula for LHS and RHS we proof the formula of $f(x)$. 
    The proof is completed by comparing $f(t)$ with $\tilde{f(t)}$.

    }
    
\end{frame}
\begin{frame}{The Two-sided Laplace inversion formula}


    {\footnotesize \scriptsize
    \par Lemma: 
    \par Consider a function \( f(x) \in C^1 \). If there exist
     a constant \( c \) and a monotone function \( \bar{f}(x) \) such that \( f(x) = e^{cx} \bar{f}(x) \), then 
     then for any \(\sigma\) in the ROAC:
     \begin{align*}
        g_{\sigma}(x) := e^{-\sigma x} f(x) = e^{(c - \sigma)x} \bar{f}(x)
     \end{align*}
     \par is of bounded variation on \(\mathbb{R}\).
     \par  \pause \textbf{Proof}:
     \par It suffices to show that, for any \(\sigma \in \text{ROAC}\), \(e^{-\sigma x} f(x)\) 
     satisfies (i) \(e^{-\sigma x} f(x) \in C^1\); (ii) \(\int_{-\infty}^{+\infty} e^{-\sigma x} |f(x)|  dx < +\infty\); 
     and (iii) \(\int_{-\infty}^{+\infty} |(e^{-\sigma x} f(x))'|  dx < +\infty\). Conditions (i) and (ii) hold obviously. 
     As regards (iii), since \(f(x) = e^{cx} \bar{f}(x)\) with \(\bar{f}(x)\) a monotone function, 
     without loss of generality, we assume that \(\bar{f}(x)\) is nondecreasing, i.e. \(\bar{f}'(x) \geq 0\). Then:
      \pause 
     \begin{align*}
        \int_{-\infty}^{+\infty} |(e^{-\sigma x} f(x))'|  dx 
        & = \int_{-\infty}^{+\infty} |(c - \sigma) e^{(c - \sigma)x} \bar{f}(x) + e^{(c - \sigma)x} \bar{f}'(x)|  dx\\
        &\leq |c - \sigma| \int_{-\infty}^{+\infty} |e^{(c - \sigma)x} \bar{f}(x)|  dx + \int_{-\infty}^{+\infty} e^{(c - \sigma)x} \bar{f}'(x)  dx\\
        &= |c - \sigma| \int_{-\infty}^{+\infty} |e^{-\sigma x} f(x)|  dx - (c - \sigma) \int_{-\infty}^{+\infty} e^{-\sigma x} f(x)  dx\\
     \end{align*}
         \vspace{-3em}
      \par The second term in last equality by using integrate by part and the boundary term vanishes.
 
    }
    
\end{frame}
\begin{frame}{Discretization errors}


    {\footnotesize \scriptsize
    \par In practice, one chooses a closed interval \([\sigma_1^*, \sigma_u^*] \subset \text{ROAC}\) to do the numerical inversion.
     Without loss of generality, we assume that \(\sigma_1^* \sigma_u^* \neq 0\), and that \(\sigma_1^*\) and \(\sigma_u^*\) are both finite. 
     The following theorem shows that introducing 
    the discretization parameter \(C\) can make the discretization error decay exponentially for \(\sigma \in (\sigma_1^*, \sigma_u^*)\).
    \vspace{1em}
    \par  \pause \textbf{Theorem}: If there exists a nonnegative function \(\delta(\cdot)\) such that, for any \(\sigma \in [\sigma_1^*, \sigma_u^*]\), 
    we have:
    \begin{align*}
        e^{-\sigma y} |f(y)| \leq \delta(\sigma) < +\infty \quad \text{for any } y
    \end{align*}
    \par then, for any fixed \( t \in \mathbb{R} \), \(\sigma \in (\sigma_1^*, \sigma_u^*)\), and \(C > 0\), we have the error bound :
    \begin{align*}
        |e_D(t, \sigma, C)| \leq \frac{\rho(\sigma, t)}{e^{\theta(\sigma)C} - 1}
    \end{align*}
    \par where \(\theta(\sigma) := 2 \min\{\sigma_u^* - \sigma, \sigma - \sigma_1^*\} > 0\) and  
    \begin{align*}
        \rho(\sigma, t) := 
    \begin{cases} 
    \delta(\sigma_u^*) e^{(2\sigma - \sigma_u^*)t} + \delta(\sigma_1^*) e^{(3\sigma_1^*-2\sigma)t} & \text{if } t \geq 0\\
    \delta(\sigma_1^*) e^{(2\sigma - \sigma_1^*)t} + \delta(\sigma_u^*) e^{(3\sigma_u^*-2\sigma)t} & \text{if } t < 0
    \end{cases}
    \end{align*}
    }
    
\end{frame}
\begin{frame}{Discretization errors}


    {\footnotesize \scriptsize
    \par Proof:
    \par From $ e^{-\sigma y} |f(y)| \leq \delta(\sigma) < +\infty \quad \text{for any } y$, we obtain:
    \begin{align*}
        |f(y)| \leq 
        \begin{cases} 
        \delta(\sigma_{1}^{*})e^{\sigma_{1}^{*}y} & \text{for any } y \geq 0 \\
        \delta(\sigma_{u}^{*})e^{\sigma_{u}^{*}y} & \text{for any } y \leq 0 \tag{1}
        \end{cases}
    \end{align*}
    \par We proceed to discuss two cases, \( t \geq 0 \) and \( t < 0 \). If \( t \geq 0 \) then, for any \( C \geq 0 \), we have:
    \begin{align*}
        2k(t + \text{sgn}(t)C) + t = 2k(t + C) + t 
        \begin{cases} 
        \geq 0 & \text{if } k > 0 \text{ and } t \geq 0 \\
        \leq 0 & \text{if } k < 0 \text{ and } t \geq 0
        \end{cases}
    \end{align*}
    \par \pause  Then by $(1)$, for any fixed \( t \geq 0 \), \( \sigma \in (\sigma_{1}^{*}, \sigma_{u}^{*}) \), and \( C > 0 \):
    \begin{align*}
          \left| e_D(t, \sigma, C) \right| & := \left| \sum_{\substack{k=-\infty \; k \neq 0}}^{+\infty} e^{-2\sigma k (t + \text{sgn}(t)C)} f(2k(t + \text{sgn}(t)C) + t)\right|\\
           & = \left| \sum_{\substack{k=-\infty \; k \neq 0}}^{+\infty}  e^{-2k(t+C)\sigma} f(2k(t + C) + t) \right|\\
           & \leq \sum_{\substack{k=-\infty \; k \neq 0}}^{+\infty}  e^{-2k(t+C)\sigma} |f(2k(t + C) + t)|
    \end{align*}
    
    }
    
\end{frame}

\begin{frame}{Discretization errors}


    {\footnotesize \scriptsize
    \par Con.
    \begin{align*}
        (by (1)) &\leq \delta(\sigma_{u}^{*}) \sum_{k=-\infty}^{-1} e^{-2k(t+C)\sigma} e^{\sigma_{u}^{*}[2k(t+C)+t]} 
        + \delta(\sigma_{1}^{*}) \sum_{k=1}^{\infty} e^{-2k(t+C)\sigma} e^{\sigma_{1}^{*}[2k(t+C)+t]}\\
        (i)&= \delta(\sigma_{u}^{*}) e^{(2\sigma - \sigma_{u}^{*})t} \frac{e^{-2C(\sigma_{u}^{*}-\sigma)}}{1 - e^{-2(t+C)(\sigma_{u}^{*}-\sigma)}} 
        + \delta(\sigma_{1}^{*}) e^{(3\sigma_{1}^{*}-2\sigma)t} \frac{e^{-2C(\sigma - \sigma_{1}^{*})}}{1 - e^{-2(t+C)(\sigma - \sigma_{1}^{*})}}\\
        & \leq \delta(\sigma_{u}^{*}) e^{(2\sigma - \sigma_{u}^{*})t} \frac{e^{-2C(\sigma_{u}^{*}-\sigma)}}{1 - e^{-2C(\sigma_{u}^{*}-\sigma)}} 
        + \delta(\sigma_{1}^{*}) e^{(3\sigma_{1}^{*}-2\sigma)t} \frac{e^{-2C(\sigma - \sigma_{1}^{*})}}{1 - e^{-2C(\sigma - \sigma_{1}^{*})}}\\
        & = \delta(\sigma_{u}^{*}) e^{(2\sigma - \sigma_{u}^{*})t} \frac{1}{e^{2C(\sigma_{u}^{*}-\sigma)} - 1} 
        + \delta(\sigma_{1}^{*}) e^{(3\sigma_{1}^{*}-2\sigma)t} \frac{1}{e^{2C(\sigma - \sigma_{1}^{*})} - 1}\\
        &\leq \frac{\rho(\sigma, t)}{e^{\theta(\sigma)C} - 1}
    \end{align*}
    \par \pause  For (i), the second term is geometric series has ratio \( r_2 = e^{-2(t+C)(\sigma - \sigma_1^*)} \in (0, 1) \). The first term is reindex $m = -k$, 
    then it is geometric series has ratio \( r_1 = e^{-2(t+C)(\sigma_{u}^{*}- \sigma)} \in (0, 1) \). For $t\geq0$, 
    this is exactly with the upper $\rho(\sigma,t)$ branch.
        \par If \( t < 0 \), we have, for any \( C \geq 0 \):
    \begin{align*}
        2k(t + \text{sgn}(t)C) + t = 2k(t - C) + t 
        \begin{cases} 
        \geq 0 & \text{if } k < 0 \text{ and } t < 0, \\ 
        \leq 0 & \text{if } k > 0 \text{ and } t < 0.
        \end{cases}
    \end{align*}
    }
    
\end{frame}
\begin{frame}{Discretization errors}


    {\footnotesize \scriptsize

    \par By (1), the discretization error for any \( t < 0 \), \( \sigma \in (\sigma_1^*, \sigma_u^*)\),
     and \( C > 0 \) can be bounded as follows:
    \begin{align*}
        \left| e_D(t, \sigma, C) \right| &= \left| \sum_{\substack{k=-\infty \; k \neq 0}}^{+\infty} e^{-2k(t-C)\sigma} f(2k(t - C) + t) \right|\\
        &\leq \sum_{\substack{k=-\infty \; k \neq 0}}^{+\infty} e^{-2k(t-C)\sigma} |f(2k(t - C) + t)|\\
        & \leq \delta(\sigma_u^*) \sum_{k=1}^\infty e^{-2k(t-C)\sigma} e^{\sigma_u^*[2k(t-C)+t]} 
        + \delta(\sigma_1^*) \sum_{k=-\infty}^{-1} e^{-2k(t-C)\sigma} e^{\sigma_1^*[2k(t-C)+t]}\\
        &= \delta(\sigma_{u}^{*})e^{(3\sigma_{u}^{*}-2\sigma)t} \frac{e^{-2C(\sigma_{u}^{*}-\sigma)}}{1-e^{-2(C-t)(\sigma_{u}^{*}-\sigma)}} 
        + \delta(\sigma_{1}^{*})e^{(2\sigma-\sigma_{1}^{*})t} \frac{e^{-2C(\sigma-\sigma_{1}^{*})}}{1-e^{-2(C-t)(\sigma-\sigma_{1}^{*})}}\\
        & \leq \delta(\sigma_{u}^{*})e^{(3\sigma_{u}^{*}-2\sigma)t} \frac{e^{-2C(\sigma_{u}^{*}-\sigma)}}{1-e^{-2C(\sigma_{u}^{*}-\sigma)}} 
        + \delta(\sigma_{1}^{*})e^{(2\sigma-\sigma_{1}^{*})t} \frac{e^{-2C(\sigma-\sigma_{1}^{*})}}{1-e^{-2C(\sigma-\sigma_{1}^{*})}}\\
        &= \delta(\sigma_{u}^{*})e^{(3\sigma_{u}^{*}-2\sigma)t} \frac{1}{e^{2C(\sigma_{u}^{*}-\sigma)}-1}
        + \delta(\sigma_{1}^{*})e^{(2\sigma-\sigma_{1}^{*})t} \frac{1}{e^{2C(\sigma-\sigma_{1}^{*})}-1}\\
        &\leq \frac{\rho(\sigma,t)}{e^{\theta(\sigma)C}-1}
    \end{align*}
    }
    
\end{frame}
\begin{frame}{Discretization errors}


    {\footnotesize \scriptsize
    \par The error bound is computable since the function \(\delta(\sigma)\) can be specified explicitly 
    in many applications. This allows practitioners to pick a sufficiently large parameter \(C\) to control discretization error.
    \vspace{1em}
    \par However, while the bound can be very small, it is hard to know how close it is to the ``true'' discretization error, 
    because the exact error formula depends on the original function \(f(\cdot)\), which is often unknown.
     \vspace{1em}
    \par  \pause The tightness of the bound varies across cases, depending heavily on \(\delta(\sigma)\) and the specific function considered.
     \vspace{1em}
    \par  Despite this uncertainty, numerical experiments in the paper show that by
    choosing a large enough \(C\), the discretization error can be reduced to a level that guarantees the desired accuracy. Even though the bound may not always be tight, 
    it is practically useful because it provides a reliable way to ensure small errors in computation.
    }
    
\end{frame}


\begin{frame}{Truncation errors}


    {\footnotesize \scriptsize
    \par The two-sided Laplace inversion formula also contains the truncation error \( e_T(t, \sigma, C, N) \). 
    \par Theorem: For any fixed \( t \in \mathbb{R} \), \( \sigma \in \text{ROAC} \), 
    and \( C \geq 0 \) such that \( |t| + C > 0 \), the following statements hold:
    \begin{itemize}
        \item (i) If there exist \( \rho > 0 \), \( \omega^* \geq 0 \), and \( \zeta(\sigma) > 0 \) such that :
        \begin{align*}
            |L_f(\sigma + i\omega)| \leq \zeta(\sigma)|\omega|^{-(1+\rho)} \quad \text{for all } |\omega| > \omega^*
        \end{align*}
        \par then the truncation error:
        \begin{align*}
            |e_T(t, \sigma, C, N)| \leq \frac{\zeta(\sigma)e^{\sigma t}(|t| + C)^\rho}{\rho\pi^{1+\rho}}N^{-\rho} = O(N^{-\rho})
        \end{align*}
        \par For any \( N \in \mathbb{N} \) such that \( N > (|t| + C)\omega^*/ \pi - 1 \).
        \item  \pause (ii) If there exist \(\beta \in \mathbb{R}\), \(\xi > 0\), \(\rho > 0\), \(\omega^* \geq 0\), and \(\zeta(\sigma) > 0\) such that:
        \begin{align*}
            |L_f(\sigma + i\omega)| \leq \zeta(\sigma)|\omega|^{-\beta}e^{-\rho|\omega|^\xi} \quad \text{for all } |\omega| > \omega^*
        \end{align*}
        \par then the truncation error:
        \begin{align*}
            |e_T(t, \sigma, C, N)| \leq \frac{\zeta(\sigma)e^{\sigma t}}{\pi \xi \rho^{(1 - \beta)/\xi}} 
            \Gamma\left( \frac{1 - \beta}{\xi}, \rho \alpha N^\xi \right) = O(N^{1 - \beta - \xi} e^{-\rho \alpha N^\xi})
        \end{align*}
        \par for any \(N \in \mathbb{N}\) such that \(N > (|t| + C)\omega^*/ \pi - 1\). Here \(\alpha := (\pi / (|t| + C))^\xi > 0\), and,
         for any \(s \in \mathbb{R}\), \(\Gamma(s, x) := \int_x^{+\infty} y^{s-1} e^{-y}  dy\) denotes the upper incomplete gamma function.
    \end{itemize}
    }
    
\end{frame}
\begin{frame}{Truncation errors}


    {\footnotesize \scriptsize
    \par Proof:
    \begin{align*}
        |e_T(t, \sigma, C, N)|&= \left|\frac{e^{\sigma t}}{|t| + C} 
       \sum_{k=N+1}^{+\infty} \left[ (-1)^k \text{Re} \left( \exp \left\{ -\frac{\text{sgn}(t)C k \pi i}{t + \text{sgn}(t)C} \right\} 
       \times L_f \left( \sigma + \frac{k \pi i}{t + \text{sgn}(t)C} \right) \right) \right]\right|\\
       & \leq \frac{e^{\sigma t}}{|t| + C} \sum_{k=N+1}^{+\infty} \left| 
        \text{Re}\left( \exp\left(-\frac{\operatorname{sgn}(t)Ck\pi i}{t + \operatorname{sgn}(t)C}\right)
        L_f\left(\sigma + \frac{k\pi i}{t + \operatorname{sgn}(t)C}\right)\right)\right|\\
        &\leq \frac{e^{\sigma t}}{|t| + C} \sum_{k=N+1}^{+\infty} \left| L_f\left(\sigma + \frac{k\pi i}{t + \operatorname{sgn}(t)C}\right)\right|\\
    \end{align*}
    \par \pause  If \( L_f(\sigma + i\omega) \) satisfies $|L_f(\sigma + i\omega)| \leq \zeta(\sigma)|\omega|^{-(1+\rho)} \quad \text{for all } |\omega| > \omega^*$ 
    then error bound follows because, for any \( N > (|t| + C)\omega^*/\pi - 1 \):
    \begin{align*}
        |e_T(t, \sigma, C, N)| &\leq \frac{e^{\sigma t}}{|t| + C} \sum_{k=N+1}^{+\infty} \zeta(\sigma) \left(\frac{k\pi}{|t| + C}\right)^{-(1+\rho)}\\
        &= \frac{\zeta(\sigma)e^{\sigma t}(|t| + C)^{\rho}}{\pi^{1+\rho}} \sum_{k=N+1}^{+\infty} k^{-(1+\rho)}\\
    \end{align*}
    }
    
\end{frame}

\begin{frame}{Truncation errors}


    {\footnotesize \scriptsize
    \par Con.
    \par Since \( k^{-(1+\rho)} \) is monotone decreasing, We now bound the tail series by an integral:
    \begin{align*}
        \sum_{k=N+1}^{\infty} k^{-(1+\rho)} \leq \int_{N}^{\infty} y^{-(1+\rho)}  dy = \frac{1}{\rho} N^{-\rho}
    \end{align*}
    \par So we obtain $|e_T(t, \sigma, C, N)| \leq \frac{\zeta(\sigma) e^{\sigma t}(|t| + C)^{\rho}}{\rho \pi^{1+\rho}} N^{-\rho}$.
    \par  \pause  Similarly, if \( L_f(\sigma + i\omega) \) satisfies $ |L_f(\sigma + i\omega)| \leq \zeta(\sigma)|\omega|^{-\beta}e^{-\rho|\omega|^\xi} \quad \text{for all } |\omega| > \omega^*$,
     we have for any \( N > (|t| + C)\omega^*/\pi - 1 \):
     \vspace{-1em}
     \begin{align*}
        |e_T(t, \sigma, C, N)|& \leq \frac{\zeta(\sigma)e^{\sigma t}\alpha^{-\beta/\xi}}{|t| + C} 
        \sum_{k=N+1}^{+\infty} k^{-\beta} e^{-\rho\alpha k^{\xi}}\\
        &\leq \frac{\zeta(\sigma)e^{\sigma t}\alpha^{-\beta/\xi}}{|t| + C} \int_{N}^{+\infty} y^{-\beta} e^{-\rho\alpha y^{\xi}}  dy\\
        &= \frac{\zeta(\sigma)e^{\sigma t}}{\pi \xi \rho^{(1-\beta)/\xi}} \Gamma \left(\frac{1 - \beta}{\xi}, \rho \alpha N^{\xi}\right)
     \end{align*}
     \par  \pause The last equality by using the substitution \( u = \rho \alpha y^\xi \),
      the integral becomes proportional to an upper incomplete gamma function. With the fact that $\lim_{x \to +\infty} \frac{\Gamma(s, x)}{x^{s-1}e^{-x}} = 1$, we end up with $O(N^{1 - \beta - \xi} e^{-\rho \alpha N^\xi})$.
    %  \par Use the fact about the asymptotic behavior of the upper incomplete gamma function,
    %   
    }
    
\end{frame}
\begin{frame}{Truncation errors}


    {\footnotesize \scriptsize
    \par The upper bounds of truncation errors depend on parameters that can be explicitly identified. Thus, for any \( C > 0 \),
     we can easily specify a sufficiently large \( N \) to control the truncation error.
    \par \pause  The two-sided Laplace inversion algorithm can be implemented to achieve any desired accuracy by controlling both discretization and truncation errors.
     For example, if the desired accuracy is \( 10^{-5} \):
     \begin{itemize}
        \item Step 1: Select a sufficiently large \( C \) such that the discretization error is below \( 5 \times 10^{-6} \).
        \item Step 2: For the fixed \( C \) selected in step 1, 
        choose a sufficiently large \( N \) such that the truncation error is below \( 5 \times 10^{-6} \).
     \end{itemize}
     \par  \pause  The parameter \(\sigma\) also effects the selection of \(C\) and \(N\), because it appears in both discretization and truncation bounds.
     \(\sigma\) interacts with functions like \(\delta(\sigma)\), \(\zeta(\sigma)\), and exponents in error terms.
     The choice of \(C\) and \(N\) thus often depends on case-by-case analysis of how \(\sigma\) influences the error.
     \par \pause  Although the value of \(\sigma\) affects the selection of \(C\) and \(N\), whatever \(\sigma\) is selected, 
     we can always use the discretization and truncation error bounds to achieve the desired accuracy by choosing sufficiently large \(C\) and \(N\). 
     Moreover, numerical examples suggest that the resulting algorithms are accurate and fast.
    }
    
\end{frame}
\begin{frame}{Next Time}

    {\footnotesize \footnotesize
    \begin{itemize}
        \item Section 6: Applications in Financial Engineering
        \item Section 7: Pricing of exotic options
        \item Section 8: Numerical examples
    \end{itemize}
    }
    
\end{frame}
%
%
%
%
% \begin{frame}

%     {\footnotesize \footnotesize

%     }
    
% \end{frame}
% % {\mathbb{P}^*}
% \tilde{\mathbb{P}}
% {\footnotesize \footnotesize
% }
% \tiny
% \scriptsize
% \footnotesize
% \small
% \normalsize (default)
\end{document}











